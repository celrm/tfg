{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862fd259",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "print (sys.version)\n",
    "print(tf.__version__)\n",
    "if tf.test.gpu_device_name(): \n",
    "    print(tf.test.is_gpu_available())\n",
    "    print(tf.test.gpu_device_name())\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80113cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"allmetrics.csv\")\n",
    "input_dim = 540 + 32 + 211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8070002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bits.csv\")\n",
    "input_dim = 32 \n",
    "df=df.replace(to_replace=\"Small\",value=\"0\")\n",
    "df=df.replace(to_replace=\"Big\",value=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59091d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02786e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bitsColsX = [ 'x{}'.format(i) for i in range(540) ]\n",
    "bitsColsR = [ 'r{}'.format(i) for i in range(32) ]\n",
    "bitsColsP = [ 'p{}'.format(i) for i in range(211) ]\n",
    "X = df.loc[:, bitsColsX + bitsColsR + bitsColsP]\n",
    "Y = df.loc[:, 'Class']\n",
    "#15% train 85% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.85, random_state=0)\n",
    "\n",
    "#We initialize data structures and the regularization parameter.\n",
    "regul_param = 10.0 ** -2\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "classifiers = []\n",
    "clf_name = []\n",
    "clf_topology = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cec112",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bitsColsBit = ['Bit'.format(i) for i in range(32) ]\n",
    "X = df.loc[:, ['Bit 31','Bit 30','Bit 29','Bit 28','Bit 27','Bit 26','Bit 25','Bit 24','Bit 23','Bit 22','Bit 21','Bit 20','Bit 19','Bit 18','Bit 17','Bit 16','Bit 15','Bit 14','Bit 13','Bit 12', 'Bit 11','Bit 10','Bit 9','Bit 8','Bit 7','Bit 6','Bit 5','Bit 4','Bit 3','Bit 2','Bit 1','Bit 0']]\n",
    "Y = df.loc[:, 'Class']\n",
    "#15% train 85% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.85, random_state=0)\n",
    "\n",
    "#We initialize data structures and the regularization parameter.\n",
    "regul_param = 10.0 ** -2\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "classifiers = []\n",
    "clf_name = []\n",
    "clf_topology = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5437ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11285a",
   "metadata": {},
   "source": [
    "# Classifier Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1beafb",
   "metadata": {},
   "source": [
    "## 100 Neuron Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf100 = Sequential()\n",
    "clf100.add(Dense(100, input_dim=input_dim, activation='relu'))\n",
    "clf100.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf100.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf100)\n",
    "clf_name.append(\"clf100\")\n",
    "clf_topology.append(\"100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5050 = Sequential()\n",
    "clf5050.add(Dense(50, input_dim=input_dim, activation='relu'))\n",
    "clf5050.add(Dense(50, activation='relu'))\n",
    "clf5050.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf5050.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf5050)\n",
    "clf_name.append(\"clf5050\")\n",
    "clf_topology.append(\"50-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f974e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf80 = Sequential()\n",
    "clf80.add(Dense(80, input_dim=input_dim, activation='relu'))\n",
    "clf80.add(Dense(15, activation='relu'))\n",
    "clf80.add(Dense(5, activation='relu'))\n",
    "clf80.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf80.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf80)\n",
    "clf_name.append(\"clf80\")\n",
    "clf_topology.append(\"80-15-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a98918",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf70 = Sequential()\n",
    "clf70.add(Dense(70, input_dim=input_dim, activation='relu'))\n",
    "clf70.add(Dense(25, activation='relu'))\n",
    "clf70.add(Dense(5, activation='relu'))\n",
    "clf70.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf70.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf70)\n",
    "clf_name.append(\"clf70\")\n",
    "clf_topology.append(\"70-25-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268122f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf525 = Sequential()\n",
    "clf525.add(Dense(50, input_dim=input_dim, activation='relu'))\n",
    "clf525.add(Dense(25, activation='relu'))\n",
    "clf525.add(Dense(25, activation='relu'))\n",
    "clf525.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf525.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf525)\n",
    "clf_name.append(\"clf525\")\n",
    "clf_topology.append(\"50-25-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee90083",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf530 = Sequential()\n",
    "clf530.add(Dense(50, input_dim=input_dim, activation='relu'))\n",
    "clf530.add(Dense(30, activation='relu'))\n",
    "clf530.add(Dense(10, activation='relu'))\n",
    "clf530.add(Dense(10, activation='relu'))\n",
    "clf530.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf530.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf530)\n",
    "clf_name.append(\"clf530\")\n",
    "clf_topology.append(\"50-30-10-10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ff812",
   "metadata": {},
   "source": [
    "## 200 Neuron Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed72f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf200 = Sequential()\n",
    "clf200.add(Dense(200, input_dim=input_dim, activation='relu'))\n",
    "clf200.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf200.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf200)\n",
    "clf_name.append(\"clf200\")\n",
    "clf_topology.append(\"200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf155 = Sequential()\n",
    "clf155.add(Dense(100, input_dim=input_dim, activation='relu'))\n",
    "clf155.add(Dense(50, activation='relu'))\n",
    "clf155.add(Dense(50, activation='relu'))\n",
    "clf155.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf155.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf155)\n",
    "clf_name.append(\"clf155\")\n",
    "clf_topology.append(\"100-50-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c7462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf160 = Sequential()\n",
    "clf160.add(Dense(160, input_dim=input_dim, activation='relu'))\n",
    "clf160.add(Dense(25, activation='relu'))\n",
    "clf160.add(Dense(10, activation='relu'))\n",
    "clf160.add(Dense(5, activation='relu'))\n",
    "clf160.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf160.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf160)\n",
    "clf_name.append(\"clf160\")\n",
    "clf_topology.append(\"160-25-10-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfd160 = Sequential()\n",
    "clfd160.add(Dense(160, input_dim=input_dim, activation='relu'))\n",
    "clfd160.add(Dropout(0.1))\n",
    "clfd160.add(Dense(25, activation='relu'))\n",
    "clfd160.add(Dropout(0.1))\n",
    "clfd160.add(Dense(10, activation='relu'))\n",
    "clfd160.add(Dropout(0.1))\n",
    "clfd160.add(Dense(5, activation='relu'))\n",
    "clfd160.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clfd160.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clfd160)\n",
    "clf_name.append(\"clfd160\")\n",
    "clf_topology.append(\"160-25-10-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb4671",
   "metadata": {},
   "source": [
    "## 800 Neuron Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b5c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfd1k = Sequential()\n",
    "clfd1k.add(Dense(600, input_dim=input_dim, activation='relu'))\n",
    "clfd1k.add(Dropout(0.1))\n",
    "clfd1k.add(Dense(160, activation='relu'))\n",
    "clfd1k.add(Dropout(0.1))\n",
    "clfd1k.add(Dense(25, activation='relu'))\n",
    "clfd1k.add(Dropout(0.1))\n",
    "clfd1k.add(Dense(10, activation='relu'))\n",
    "clfd1k.add(Dropout(0.1))\n",
    "clfd1k.add(Dense(5, activation='relu'))\n",
    "clfd1k.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clfd1k.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clfd1k)\n",
    "clf_name.append(\"clfd800\")\n",
    "clf_topology.append(\"600-160-25-10-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b744451",
   "metadata": {},
   "source": [
    "## 1600 Neuron Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1888c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfd1k6 = Sequential()\n",
    "clfd1k6.add(Dense(800, input_dim=input_dim, activation='relu'))\n",
    "clfd1k6.add(Dropout(0.1))\n",
    "clfd1k6.add(Dense(600, activation='relu'))\n",
    "clfd1k6.add(Dropout(0.1))\n",
    "clfd1k6.add(Dense(160, activation='relu'))\n",
    "clfd1k6.add(Dropout(0.1))\n",
    "clfd1k6.add(Dense(25, activation='relu'))\n",
    "clfd1k6.add(Dropout(0.1))\n",
    "clfd1k6.add(Dense(10, activation='relu'))\n",
    "clfd1k6.add(Dropout(0.1))\n",
    "clfd1k6.add(Dense(5, activation='relu'))\n",
    "clfd1k6.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clfd1k6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clfd1k6)\n",
    "clf_name.append(\"clfd1k6\")\n",
    "clf_topology.append(\"800-600-160-25-10-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0aaa4e",
   "metadata": {},
   "source": [
    "## 2000 Neuron Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61df209",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2k = Sequential()\n",
    "clf2k.add(Dense(1200, input_dim=input_dim, activation='relu'))\n",
    "clf2k.add(Dense(400, activation='relu'))\n",
    "clf2k.add(Dense(200, activation='relu'))\n",
    "clf2k.add(Dense(120, activation='relu'))\n",
    "clf2k.add(Dense(55, activation='relu'))\n",
    "clf2k.add(Dense(20, activation='relu'))\n",
    "clf2k.add(Dense(5, activation='relu'))\n",
    "clf2k.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf2k.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf2k)\n",
    "clf_name.append(\"clf2k\")\n",
    "clf_topology.append(\"1200-400-200-120-55-20-5-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfd2k = Sequential()\n",
    "clfd2k.add(Dense(1200, input_dim=input_dim, activation='relu'))\n",
    "clfd160.add(Dropout(0.1))\n",
    "clfd2k.add(Dense(400, activation='relu'))\n",
    "clfd160.add(Dropout(0.1))\n",
    "clfd2k.add(Dense(200, activation='relu'))\n",
    "clfd160.add(Dropout(0.1))\n",
    "clfd2k.add(Dense(120, activation='relu'))\n",
    "clfd160.add(Dropout(0.1))\n",
    "clfd2k.add(Dense(55, activation='relu'))\n",
    "clfd160.add(Dropout(0.1))\n",
    "clfd2k.add(Dense(20, activation='relu'))\n",
    "clfd160.add(Dropout(0.1))\n",
    "clfd2k.add(Dense(5, activation='relu'))\n",
    "clfd2k.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clfd2k.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf2k)\n",
    "clf_name.append(\"clfd2k\")\n",
    "clf_topology.append(\"1200-400-200-120-55-20-5-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e13fd",
   "metadata": {},
   "source": [
    "# Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong_predictions(model,name):\n",
    "    predictions = []\n",
    "    y_pred = model.predict_classes(X_test).flatten()\n",
    "    for y in y_pred:\n",
    "        predictions.append(str(y))\n",
    "    wrong_pred = X_test[predictions != y_test].index\n",
    "    wrong_elements = df.iloc[wrong_pred].loc[:,['Function','Class']]\n",
    "    wrong_elements.to_csv('misses/wrong_%s.csv'%name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d07ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clfnum = 0\n",
    "for clf in classifiers:\n",
    "    train = []\n",
    "    test = []\n",
    "    num_epochs= 5\n",
    "    runs = 1\n",
    "    save_model = True\n",
    "    save_wrong = True\n",
    "    for i in range(runs):\n",
    "        clfaux= tf.keras.models.clone_model(clf)\n",
    "        filename = clf_name[clfnum] + \"_#\" + str(i+1)\n",
    "        print(\"Classifier: \", filename)\n",
    "        print(\"Compiling...\")\n",
    "        clfaux.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        print(\"Training...\")\n",
    "        clfaux.fit(X_train, y_train, epochs=num_epochs, batch_size=16384,verbose = 0)\n",
    "        print(\"Computing train score...\")\n",
    "        tr_score = clfaux.evaluate(X_train, y_train, verbose = 0)[1]\n",
    "        print(tr_score)\n",
    "        train.append(tr_score)\n",
    "        print(\"Computing test score...\")\n",
    "        ts_score = clfaux.evaluate(X_test, y_test, verbose = 0)[1]\n",
    "        print(ts_score)\n",
    "        test.append(ts_score)\n",
    "        \n",
    "        if(save_model):\n",
    "            print(\"Saving model...\")\n",
    "            clfaux.save('models/%s.clf'%filename)\n",
    "        if(save_wrong):\n",
    "            print(\"Saving wrong predictions...\")\n",
    "            wrong_predictions(clfaux,filename)\n",
    "        \n",
    "    clfnum += 1    \n",
    "    train_scores.append(train)\n",
    "    test_scores.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b003e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19f2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(clf_name)\n",
    "print(clf_topology)\n",
    "print(train_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30329f53",
   "metadata": {},
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "train_err = []\n",
    "test_err = []\n",
    "\n",
    "for i in range(len(clf_name)):\n",
    "    train.append(np.mean(train_scores[i]))\n",
    "    train_err.append(np.std(train_scores[i]))\n",
    "    test.append(np.mean(test_scores[i]))\n",
    "    test_err.append(np.std(test_scores[i]))\n",
    "means = pd.DataFrame({'Train': train,'Test': test}, index=clf_topology)\n",
    "errors = pd.DataFrame({'Train': train_err,'Test': test_err}, index=clf_topology)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59638e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b9aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pd.DataFrame({'Train': train,'Test': test}, index=clf_topology)\n",
    "errors = pd.DataFrame({'Train': train_err,'Test': test_err}, index=clf_topology)\n",
    "\n",
    "sup = 1.005*max(max(train),max(test))\n",
    "inf = 0.995*min(min(train),min(test))\n",
    "ax = means.plx = means.plot.bar(rot=0,yerr=errors,figsize=(12,10),ylim=[inf,sup],capsize=4, xlabel= \"Topology\", ylabel= \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130fad98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
