{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "print (sys.version)\n",
    "print(tf.__version__)\n",
    "if tf.test.gpu_device_name(): \n",
    "    print(tf.test.is_gpu_available())\n",
    "    print(tf.test.gpu_device_name())\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"result.csv\")\n",
    "input_dim = 95 + 32 + 211\n",
    "\n",
    "bitsColsX = [ 'x{}'.format(i) for i in range(95) ]\n",
    "bitsColsR = [ 'r{}'.format(i) for i in range(32) ]\n",
    "bitsColsP = [ 'p{}'.format(i) for i in range(211) ]\n",
    "X = df.loc[:, bitsColsX + bitsColsR + bitsColsP]\n",
    "Y = df.loc[:, 'Class']\n",
    "#15% train 85% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.85, random_state=0)\n",
    "\n",
    "#We initialize data structures and the regularization parameter.\n",
    "regul_param = 10.0 ** -2\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "classifiers = []\n",
    "clf_name = []\n",
    "clf_topology = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classifier Definitions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 100 Neuron Classifiers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf100 = Sequential()\n",
    "clf100.add(Dense(100, input_dim=input_dim, activation='relu'))\n",
    "clf100.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf100.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf100)\n",
    "clf_name.append(\"clf100\")\n",
    "clf_topology.append(\"100\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf5050 = Sequential()\n",
    "clf5050.add(Dense(50, input_dim=input_dim, activation='relu'))\n",
    "clf5050.add(Dense(50, activation='relu'))\n",
    "clf5050.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf5050.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf5050)\n",
    "clf_name.append(\"clf5050\")\n",
    "clf_topology.append(\"50-50\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf80 = Sequential()\n",
    "clf80.add(Dense(80, input_dim=input_dim, activation='relu'))\n",
    "clf80.add(Dense(15, activation='relu'))\n",
    "clf80.add(Dense(5, activation='relu'))\n",
    "clf80.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf80.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf80)\n",
    "clf_name.append(\"clf80\")\n",
    "clf_topology.append(\"80-15-5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf70 = Sequential()\n",
    "clf70.add(Dense(70, input_dim=input_dim, activation='relu'))\n",
    "clf70.add(Dense(25, activation='relu'))\n",
    "clf70.add(Dense(5, activation='relu'))\n",
    "clf70.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf70.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf70)\n",
    "clf_name.append(\"clf70\")\n",
    "clf_topology.append(\"70-25-5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf525 = Sequential()\n",
    "clf525.add(Dense(50, input_dim=input_dim, activation='relu'))\n",
    "clf525.add(Dense(25, activation='relu'))\n",
    "clf525.add(Dense(25, activation='relu'))\n",
    "clf525.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf525.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf525)\n",
    "clf_name.append(\"clf525\")\n",
    "clf_topology.append(\"50-25-25\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf530 = Sequential()\n",
    "clf530.add(Dense(50, input_dim=input_dim, activation='relu'))\n",
    "clf530.add(Dense(30, activation='relu'))\n",
    "clf530.add(Dense(10, activation='relu'))\n",
    "clf530.add(Dense(10, activation='relu'))\n",
    "clf530.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf530.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf530)\n",
    "clf_name.append(\"clf530\")\n",
    "clf_topology.append(\"50-30-10-10\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 200 Neuron Classifiers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf200 = Sequential()\n",
    "clf200.add(Dense(200, input_dim=input_dim, activation='relu'))\n",
    "clf200.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf200.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf200)\n",
    "clf_name.append(\"clf200\")\n",
    "clf_topology.append(\"200\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf155 = Sequential()\n",
    "clf155.add(Dense(100, input_dim=input_dim, activation='relu'))\n",
    "clf155.add(Dense(50, activation='relu'))\n",
    "clf155.add(Dense(50, activation='relu'))\n",
    "clf155.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf155.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf155)\n",
    "clf_name.append(\"clf155\")\n",
    "clf_topology.append(\"100-50-50\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf160 = Sequential()\n",
    "clf160.add(Dense(160, input_dim=input_dim, activation='relu'))\n",
    "clf160.add(Dense(25, activation='relu'))\n",
    "clf160.add(Dense(10, activation='relu'))\n",
    "clf160.add(Dense(5, activation='relu'))\n",
    "clf160.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "clf160.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "classifiers.append(clf160)\n",
    "clf_name.append(\"clf160\")\n",
    "clf_topology.append(\"160-25-10-5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training & Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\n",
    "clfnum = 0\n",
    "for clf in classifiers:\n",
    "    train = []\n",
    "    test = []\n",
    "    runs = 10\n",
    "    for i in range(runs):\n",
    "        print(\"Classifier: \", (clfnum +1), \" Run: \", (i+1))\n",
    "        clfaux= tf.keras.models.clone_model(clf)\n",
    "        clfaux.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        clfaux.fit(X_train, y_train, epochs=300, batch_size=16384,verbose = 0)\n",
    "        train.append(clfaux.evaluate(X_train, y_train, verbose = 0)[1])\n",
    "        test.append(clfaux.evaluate(X_test, y_test, verbose = 0)[1])\n",
    "        filename = 'trained_models/'+clf_name[clfnum] +'_v' + str(i+1) +'.joblib'\n",
    "        clfaux.save(filename)\n",
    "    clfnum += 1    \n",
    "    train_scores.append(train)\n",
    "    test_scores.append(test)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(clf_name)\n",
    "print(clf_topology)\n",
    "print(train_scores)\n",
    "print(test_scores)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results Visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train = []\n",
    "test = []\n",
    "train_err = []\n",
    "test_err = []\n",
    "\n",
    "for i in range(len(clf_name)):\n",
    "    train.append(np.mean(train_scores[i]))\n",
    "    train_err.append(np.std(train_scores[i]))\n",
    "    test.append(np.mean(test_scores[i]))\n",
    "    test_err.append(np.std(test_scores[i]))\n",
    "means = pd.DataFrame({'Train': train,'Test': test}, index=clf_topology)\n",
    "errors = pd.DataFrame({'Train': train_err,'Test': test_err}, index=clf_topology)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "means"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "errors"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "means = pd.DataFrame({'Train': train,'Test': test}, index=clf_topology)\n",
    "errors = pd.DataFrame({'Train': train_err,'Test': test_err}, index=clf_topology)\n",
    "\n",
    "sup = 1.005*max(max(train),max(test))\n",
    "inf = 0.995*min(min(train),min(test))\n",
    "ax = means.plx = means.plot.bar(rot=0,yerr=errors,figsize=(12,10),ylim=[inf,sup],capsize=4, xlabel= \"Topology\", ylabel= \"Accuracy\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}